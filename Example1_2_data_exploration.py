"""
This script is dedicated to data exploration and visualizations.

Here we will load the data generated by the previous script, including
the train and test sets.  After that we will plot each variable vs each
other, using only the training set (we want to leave the test set as a
black box, so we don't induce any unnecessary bias).

Guided by the generated plot, we execute some transformations on the
data, so it seems more linearly correlated, and make another exploratory
visualization.  Then, we compute the correlation matrix and plot it.
"""

# Import necessary packages
import numpy as np
import os

import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split

from statistical_plots import plot_each_vs_each, plot_correlation_matrix


# Import Clean Data
data_dir = 'Clean Data'
exports = np.genfromtxt(os.path.abspath(data_dir+'/'+'Exports_Clean.csv'), delimiter=',')
gdp = np.genfromtxt(os.path.abspath(data_dir+'/'+'GDP_Clean.csv'), delimiter=',')
pol_stab = np.genfromtxt(os.path.abspath(data_dir+'/'+'Pol_Stab_Clean.csv'), delimiter=',')
reg_quality = np.genfromtxt(os.path.abspath(data_dir+'/'+'Reg_Quality_Clean.csv'), delimiter=',')
timestamps = np.array(np.arange(2012,2022))

# Generate a train and test set, so we don't see the test set on visualizations
gdp_train, gdp_test, exports_train, exports_test, pol_train, pol_test, reg_train, reg_test = train_test_split(gdp, exports, pol_stab, reg_quality, train_size=0.75, random_state=42)

# Create the directory (if it doesn't exists already) to save visualizations
vis_dir = 'Visualizations'
if not os.path.exists(vis_dir):
    os.mkdir(vis_dir)

# Plot each variable against the others
data = np.concatenate((gdp_train, exports_train, pol_train, reg_train), axis=1)
labels = ['GDP per capita', 'Exports', 'Political Stability', 'Regulatory Quality']
fig_suptitle = 'Variables vs each other (dot size=timestamp)'
fig_explor, axs_explor = plot_each_vs_each(data, labels, n_timestamps=timestamps.size, scale=(6.4*2, 4.8*2), suptitle=fig_suptitle, style='ro', ms=timestamps-2011)

vis_file = 'Data Exploration.png'
fig_explor.savefig(os.path.abspath(vis_dir+'/'+vis_file),bbox_inches='tight')

# It seems to be more convinient to replicate the same plot with log(gdp) and log(exports)
data = np.concatenate((np.log(gdp_train), np.log(exports_train), pol_train, reg_train), axis=1)
labels = ['log(GDP per capita)', 'log(Exports)', 'Political Stability', 'Regulatory Quality']
fig_suptitle = 'Variables vs each other (dot size=timestamp)'
fig_log_explor, axs_log_explor = plot_each_vs_each(data, labels, n_timestamps=timestamps.size, scale=(6.4*2, 4.8*2), suptitle=fig_suptitle, style='ro', ms=timestamps-2011)

vis_file = 'Data Exploration Log.png'
fig_log_explor.savefig(os.path.abspath(vis_dir+'/'+vis_file),bbox_inches='tight')

# Now, we flatten the variables to compute the correlation matrix
gdp_train = np.log(gdp_train).flatten()
exports_train = np.log(exports_train).flatten()
pol_train = pol_train.flatten()
reg_train = reg_train.flatten()

gdp_test = np.log(gdp_test).flatten()
exports_test = np.log(exports_test).flatten()
pol_test = pol_test.flatten()
reg_test = reg_test.flatten()

# We stack the data together
data_train = np.stack((gdp_train, exports_train, pol_train, reg_train),axis=0).T
data_test = np.stack((gdp_test, exports_test, pol_test, reg_test),axis=0).T

# Calculate the correlation matrix
corr_matrix = np.corrcoef(x=data_train, rowvar=False)
print('Correlation Matrix: \n', corr_matrix, '\n')

# Plot the correlation matrix as a heat map
labels = ['log(GDP per capita)', 'log(Exports)', 'Political Stability', 'Regulatory Quality']
fig_suptitle = "Correlation Matrix"
fig_corr, ax_corr = plot_correlation_matrix(corr_matrix, labels, suptitle=fig_suptitle)

vis_file='Correlation Matrix.png'
fig_corr.savefig(os.path.abspath(vis_dir+'/'+vis_file),bbox_inches='tight')

# Save the train and test sets
np.savetxt(os.path.abspath(data_dir+'/'+'Train_data.csv'), data_train, delimiter=",")
np.savetxt(os.path.abspath(data_dir+'/'+'Test_data.csv'), data_test, delimiter=",")